{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.ModelInspector import ModelInspector\n",
    "from DataSynthesizer.lib.utils import read_json_file, display_bayesian_network\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-defined parameteres\n",
    "\n",
    "the input_data_files list of dictionaries consists of 4 keys.\n",
    "- input_file_path\n",
    "- candidate_keys\n",
    "- primary_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_data_files = [{\n",
    "    \"input_file_path\":\"/data/datafiles/yelp_academic_dataset_business_transformed.CSV\"\n",
    "    ,\"candidate_keys\": [\"business_id\",\"name\"]\n",
    "    ,\"foreign_keys\": []\n",
    "    ,\"drop_columns\": [\"hours\",\"hours.Monday\",\"hours.Tuesday\",\"hours.Wednesday\",\"hours.Thursday\",\"hours.Friday\",\"hours.Saturday\",\"hours.Sunday\"\n",
    "    ,\"postal_code\",\"attributes.ByAppointmentOnly\",\"attributes.BusinessAcceptsCreditCards\",\"attributes.BikeParking\",\"attributes.RestaurantsPriceRange2\",\"attributes.CoatCheck\",\"attributes.RestaurantsTakeOut\",\"attributes.RestaurantsDelivery\",\"attributes.Caters\",\"attributes.WiFi\",\"attributes.BusinessParking.garage\",\"attributes.BusinessParking.street\",\"attributes.BusinessParking.validated\",\"attributes.BusinessParking.lot\",\"attributes.BusinessParking.valet\",\"attributes.WheelchairAccessible\",\"attributes.HappyHour\",\"attributes.OutdoorSeating\",\"attributes.HasTV\",\"attributes.RestaurantsReservations\",\"attributes.DogsAllowed\",\"attributes.Alcohol\",\"attributes.GoodForKids\",\"attributes.RestaurantsAttire\",\"attributes.RestaurantsTableService\",\"attributes.RestaurantsGoodForGroups\",\"attributes.DriveThru\",\"attributes.NoiseLevel\",\"attributes.Ambience.romantic\",\"attributes.Ambience.intimate\",\"attributes.Ambience.touristy\",\"attributes.Ambience.hipster\",\"attributes.Ambience.divey\",\"attributes.Ambience.classy\",\"attributes.Ambience.trendy\",\"attributes.Ambience.upscale\",\"attributes.Ambience.casual\",\"attributes.GoodForMeal.dessert\",\"attributes.GoodForMeal.latenight\",\"attributes.GoodForMeal.lunch\",\"attributes.GoodForMeal.dinner\",\"attributes.GoodForMeal.brunch\",\"attributes.GoodForMeal.breakfast\",\"attributes.BusinessAcceptsBitcoin\",\"attributes.Smoking\",\"attributes.Music.dj\",\"attributes.Music.background_music\",\"attributes.Music.no_music\",\"attributes.Music.jukebox\",\"attributes.Music.live\",\"attributes.Music.video\",\"attributes.Music.karaoke\",\"attributes.GoodForDancing\",\"attributes.AcceptsInsurance\",\"attributes.BestNights.monday\",\"attributes.BestNights.tuesday\",\"attributes.BestNights.friday\",\"attributes.BestNights.wednesday\",\"attributes.BestNights.thursday\",\"attributes.BestNights.sunday\",\"attributes.BestNights.saturday\",\"attributes.BYOB\",\"attributes.Corkage\",\"attributes.BYOBCorkage\",\"attributes.HairSpecializesIn.straightperms\",\"attributes.HairSpecializesIn.coloring\",\"attributes.HairSpecializesIn.extensions\",\"attributes.HairSpecializesIn.africanamerican\",\"attributes.HairSpecializesIn.curly\",\"attributes.HairSpecializesIn.kids\",\"attributes.HairSpecializesIn.perms\",\"attributes.HairSpecializesIn.asian\",\"attributes.Open24Hours\",\"attributes.RestaurantsCounterService\",\"attributes.AgesAllowed\",\"attributes.DietaryRestrictions.dairy-free\",\"attributes.DietaryRestrictions.gluten-free\",\"attributes.DietaryRestrictions.vegan\",\"attributes.DietaryRestrictions.kosher\",\"attributes.DietaryRestrictions.halal\",\"attributes.DietaryRestrictions.soy-free\",\"attributes.DietaryRestrictions.vegetarian\"\n",
    "    ,\"address\",\"state\",\"latitude\",\"longitude\",\"categories5\",\"categories6\",\"categories7\",\"categories8\",\"categories9\",\"categories10\",\"categories11\",\"categories12\",\"categories13\",\"categories14\",\"categories15\",\"categories16\",\"categories17\",\"categories18\",\"categories19\",\"categories20\",\"categories21\",\"categories22\"\n",
    "    ]\n",
    "},\n",
    "{\n",
    "    \"input_file_path\":\"/data/datafiles/yelp_academic_dataset_review_transformed.CSV\"\n",
    "    ,\"candidate_keys\": [\"business_id\"]\n",
    "    ,\"foreign_keys\": [{\n",
    "        \"foreign_key\": \"business_id\"\n",
    "        ,\"reference_file\": \"/data/datafiles/yelp_academic_dataset_business_transformed.CSV\"\n",
    "        ,\"reference_key\": \"business_id\"\n",
    "    }]\n",
    "    ,\"drop_columns\": [\"text\"]\n",
    "},\n",
    "{\n",
    "    \"input_file_path\":\"/data/datafiles/yelp_academic_dataset_user_transformed.CSV\"\n",
    "    ,\"candidate_keys\": [\"user_id\"]\n",
    "    ,\"foreign_keys\": [{\n",
    "        \"foreign_key\": \"user_id\"\n",
    "        ,\"reference_file\": \"/data/datafiles/yelp_academic_dataset_review_transformed.CSV\"\n",
    "        ,\"reference_key\": \"user_id\"\n",
    "    }]\n",
    "    ,\"drop_columns\": [\"useful\",\"funny\",\"cool\",\"elite\",\"friends\",\"fans\",\"average_stars\",\"compliment_hot\",\"compliment_more\",\"compliment_profile\",\"compliment_cute\",\"compliment_list\",\"compliment_note\",\"compliment_plain\",\"compliment_cool\",\"compliment_funny\",\"compliment_writer\",\"compliment_photos\"]\n",
    "}]\n",
    "\n",
    "\n",
    "# A filter of number of Rows, use this when you want to filter a number of rows \n",
    "# in a big dataset in order to use the Data Synthesizer Frontend. Use 0 if you want to retrieve all rows\n",
    "numberOfRowsFilter = 20000\n",
    "\n",
    "# location of two output files\n",
    "mode = 'independent_attribute_mode'\n",
    "destination_file_folder = f'/data/datafiles/out/{mode}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attribute is categorical if its domain size is less than this threshold.\n",
    "# Here modify the threshold to adapt to the domain size of \"education\" (which is 14 in input dataset).\n",
    "threshold_value = 20 \n",
    "\n",
    "\n",
    "# Number of tuples generated in synthetic dataset.\n",
    "num_tuples_to_generate = 20000 # Here 32561 is the same as input dataset, but it can be set to another number."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for Data Synthesizer\n",
    "\n",
    "1. Data Synthesizer has some requirements for the dataset (for example, no boolean datatypes or columns which have 0 values)\n",
    "2. To accomodate to these requirements, the dataset will be prepared in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "filtered_output_files: list = []\n",
    "\n",
    "def prepare_dataframe_for_synthesizer(df: DataFrame, dropColumns: list, foreignKeys) -> DataFrame:\n",
    "    #replace boolean values by bit, because synthesizer does not accept boolean type\n",
    "    df =df.replace(True,1)\n",
    "    df = df.replace(False,0)\n",
    "    df = df.drop(columns=dropColumns) if len(dropColumns) > 0 else df\n",
    "    #drop columns which are empty\n",
    "    df.dropna(how='all', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_input_df(input_data_file) -> DataFrame:\n",
    "    inputDf: pd.DataFrame()\n",
    "    foreignKeys =input_data_file['foreign_keys']\n",
    "    if len(foreignKeys) == 0:\n",
    "        inputDf = pd.read_csv(filepath_or_buffer=input_data_file['input_file_path']\n",
    "                                                ,sep=\";\"\n",
    "                                                ,nrows=numberOfRowsFilter\n",
    "                                                ,low_memory=False) \n",
    "    if len(foreignKeys) > 0:\n",
    "        #only get related foreign key records when foreign keys are defined\n",
    "        for foreignKey in foreignKeys:\n",
    "            foreign_key_reference_file_path = f\"{os.path.dirname(foreignKey['reference_file'])}/{os.path.basename(foreignKey['reference_file']).split('.')[0]}_filtered.csv\"\n",
    "            foreign_key_df: pd.DataFrame = pd.read_csv(filepath_or_buffer=foreign_key_reference_file_path\n",
    "                                                ,sep=\",\"\n",
    "                                                ,low_memory=False)[foreignKey['reference_key']]\n",
    "\n",
    "            foreign_key_df_list = foreign_key_df.to_list()\n",
    "\n",
    "            for chunk in pd.read_csv(filepath_or_buffer=input_data_file['input_file_path']\n",
    "                                                ,sep=\";\"\n",
    "                                                , chunksize=10000):\n",
    "                if 'inputDf' in locals():           \n",
    "                    inputDf = pd.concat([inputDf,chunk[chunk[foreignKey['foreign_key']].isin(foreign_key_df_list)]])\n",
    "                else:\n",
    "                    inputDf = chunk[chunk[foreignKey['foreign_key']].isin(foreign_key_df_list)]\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    return inputDf\n",
    "\n",
    "#filter input files based on numberOfRows Parameter\n",
    "for input_data_file in input_data_files:\n",
    "    filtered_output_data = {\"filtered_output_path\": f\"{os.path.dirname(input_data_file['input_file_path'])}/{os.path.basename(input_data_file['input_file_path']).split('.')[0]}_filtered.csv\"\n",
    "                                            ,\"candidate_keys\": input_data_file['candidate_keys']\n",
    "                                            ,\"description_file_path\": f\"{destination_file_folder}/{os.path.basename(input_data_file['input_file_path']).split('.')[0]}_description.json\"\n",
    "                                            ,\"synthetic_file_path\": f\"{destination_file_folder}/{os.path.basename(input_data_file['input_file_path']).split('.')[0]}_synthentic.csv\"\n",
    "                                            }\n",
    "    filtered_output_files.append(filtered_output_data)  \n",
    "    if numberOfRowsFilter > 0:\n",
    "        inputDf = get_input_df(input_data_file=input_data_file)                              \n",
    "        inputDf = prepare_dataframe_for_synthesizer(inputDf,dropColumns=input_data_file['drop_columns'], foreignKeys=input_data_file['foreign_keys'])\n",
    "        inputDf.to_csv(f\"{filtered_output_data['filtered_output_path']}\"\n",
    "                        ,sep=\",\"\n",
    "                        ,index=False\n",
    "                        ,quoting = csv.QUOTE_NONNUMERIC)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataDescriber\n",
    "\n",
    "1. Instantiate a DataDescriber.\n",
    "2. Compute the statistics of the dataset.\n",
    "3. Save dataset description to a file on local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filtered_data_file in filtered_output_files:\n",
    "        filteredDf: pd.DataFrame = pd.read_csv(filepath_or_buffer=filtered_data_file['filtered_output_path']\n",
    "                                                ,sep=\",\"\n",
    "                                                ,low_memory=False) \n",
    "        \n",
    "        columns: pd.Index = filteredDf.columns\n",
    "\n",
    "        categorical_attributes = {x:True for x in filteredDf.columns if x not in filtered_data_file['candidate_keys']}\n",
    "        candidate_keys = {x:True for x in filtered_data_file['candidate_keys']}\n",
    "        print(threshold_value)\n",
    "        describer: DataDescriber = DataDescriber(category_threshold=threshold_value)\n",
    "        print(categorical_attributes)\n",
    "        print(filtered_data_file['filtered_output_path'])\n",
    "        describer.describe_dataset_in_independent_attribute_mode(dataset_file=filtered_data_file['filtered_output_path'],\n",
    "                                                                epsilon=10,\n",
    "                                                                attribute_to_is_categorical=categorical_attributes,\n",
    "                                                                attribute_to_is_candidate_key=candidate_keys\n",
    "                                                                ,seed=0)\n",
    "        describer.save_dataset_description_to_file(filtered_data_file['description_file_path'])\n",
    "\n",
    "        ### Step 4 generate synthetic dataset\n",
    "\n",
    "        #1. Instantiate a DataGenerator.\n",
    "        #2. Generate a synthetic dataset.\n",
    "        #3. Save it to local machine.\n",
    "        generator: DataGenerator = DataGenerator()\n",
    "\n",
    "        generator.generate_dataset_in_independent_mode(num_tuples_to_generate, filtered_data_file['description_file_path'])\n",
    "        generator.save_synthetic_data(filtered_data_file['synthetic_file_path'],seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the statistics of input and sythetic data (optional)\n",
    "\n",
    "The synthetic data is already saved in a file by step 4. The ModelInspector is for a quick test on the similarity between input and synthetic datasets.\n",
    "\n",
    "#### instantiate a ModelInspector.\n",
    "\n",
    "It needs input dataset, synthetic dataset, and attribute description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filtered_data_file in filtered_output_files:\n",
    "        # Read both datasets using Pandas.\n",
    "        filteredDf: pd.DataFrame = pd.read_csv(filepath_or_buffer=filtered_data_file['filtered_output_path']\n",
    "                                                ,sep=\",\") \n",
    "        syntheticDf: pd.DataFrame = pd.read_csv(filepath_or_buffer=filtered_data_file['synthetic_file_path']\n",
    "                                                ,sep=\",\") \n",
    "        # Read attribute description from the dataset description file.\n",
    "        attribute_description = read_json_file(filtered_data_file['description_file_path'])['attribute_description']\n",
    "        inspector: ModelInspector = ModelInspector(filteredDf, syntheticDf, attribute_description)\n",
    "        inspector.mutual_information_heatmap()\n",
    "        #for attribute in syntheticDf.columns:\n",
    "        #        inspector.compare_histograms(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector.mutual_information_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
